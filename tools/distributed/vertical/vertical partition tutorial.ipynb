{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8236085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-                                                                        \n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import onnx\n",
    "from onnx import helper, checker\n",
    "from onnx import TensorProto\n",
    "import os, psutil\n",
    "\n",
    "# import autodice functions .\n",
    "from code_generator import CppFile\n",
    "from cpp_generator import *\n",
    "from onnx_split import *\n",
    "from data_json import *\n",
    "from interface import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117811a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MODEL has total 24 layers.\n"
     ]
    }
   ],
   "source": [
    "origin_model = \"bvlcalexnet-9.onnx\"\n",
    "input_model = format_onnx(origin_model)  # name all layers according to their output tensor name\n",
    "model =  onnx.load(input_model) \n",
    "model_len = len(model.graph.node)\n",
    "\n",
    "resourceid = { 1:'nx01_arm012345', 2:'nx01_gpu'}\n",
    "platforms = ['nx01']\n",
    "cnn_map = {\n",
    "        'nx01_arm012345': ['conv1_1', 'conv1_2', 'norm1_1', \n",
    "            'pool1_1', 'conv2_1', 'conv2_2', 'norm2_1', 'pool2_1', 'conv3_1', \n",
    "            'conv3_2', 'conv4_1', 'conv4_2', 'conv5_1', 'conv5_2', 'pool5_1', \n",
    "            'OC2_DUMMY_0', 'fc6_1', 'fc6_2'], \n",
    "        'nx01_gpu': ['fc6_3', 'fc7_1', 'fc7_2', 'fc7_3', 'fc8_1', 'prob_1']}\n",
    "\n",
    "# CNN Mapping:  \n",
    "# {'nx01_arm012345': ['conv1_1', 'conv1_2', 'norm1_1', \n",
    "# 'pool1_1', 'conv2_1', 'conv2_2', 'norm2_1', 'pool2_1', 'conv3_1', \n",
    "# 'conv3_2', 'conv4_1', 'conv4_2', 'conv5_1', 'conv5_2', 'pool5_1', \n",
    "# 'OC2_DUMMY_0', 'fc6_1', 'fc6_2'], \n",
    "# 'nx01_gpu': ['fc6_3', 'fc7_1', 'fc7_2', 'fc7_3', 'fc8_1', 'prob_1']}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda1a2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output directory ./models is created!\n",
      "Total GPU: 1, Total CPU: 6\n",
      "Consistency Check Pass.\n",
      "Devices: 1\n",
      "Generate  2  Sub-Models.\n",
      "Front End time: 5.287814 (s)\n"
     ]
    }
   ],
   "source": [
    "# call interface function to generate onnx models\n",
    "# Check whether the specified path exists or not\n",
    "output_dirs= './models'\n",
    "if not os.path.exists(output_dirs):\n",
    "  # Create a new directory because it does not exist \n",
    "  os.makedirs(output_dirs)\n",
    "  print(\"The output directory %s is created!\" % (output_dirs))\n",
    "\n",
    "start_time = time.time()\n",
    "InputSpecs = Interface(model=input_model, mappings=cnn_map, platforms=platforms)\n",
    "print (\"Front End time: %f (s)\"%(time.time() - start_time))\n",
    "output_dirs = 'models'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d29a3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cpp code \n",
    "GenerateCode = EngineCode(\n",
    "    CppName = \"./models/multinode\",\n",
    "    Platforms = InputSpecs.platforms,\n",
    "    NodesList = InputSpecs.nodes,\n",
    "    ComputingNodes = InputSpecs.computingnodes,\n",
    "    ValueInfos = InputSpecs.value_map,\n",
    "    Inputs = InputSpecs.inputs,\n",
    "    Outputs = InputSpecs.outputs,\n",
    "    Benchmark = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
