{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8236085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-                                                                        \n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import onnx\n",
    "from onnx import helper, checker\n",
    "from onnx import TensorProto\n",
    "import os, psutil\n",
    "from onnx import numpy_helper\n",
    "from onnx import AttributeProto, TensorProto, GraphProto\n",
    "\n",
    "# import autodice functions .\n",
    "\n",
    "from code_generator import CppFile\n",
    "from cpp_generator import *\n",
    "from onnx_split import *\n",
    "from data_json import *\n",
    "from interface import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117811a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MODEL has total 24 layers.\n",
      "Split Convolution Layer (LIP--Width)  conv2_1\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# CNN Mapping:  \n",
    "# {'nx01_arm012345': ['conv1_1', 'conv1_2', 'norm1_1', \n",
    "# 'pool1_1', 'conv2_1', 'conv2_2', 'norm2_1', 'pool2_1', 'conv3_1', \n",
    "# 'conv3_2', 'conv4_1', 'conv4_2', 'conv5_1', 'conv5_2', 'pool5_1', \n",
    "# 'OC2_DUMMY_0', 'fc6_1', 'fc6_2'], \n",
    "# 'nx01_gpu': ['fc6_3', 'fc7_1', 'fc7_2', 'fc7_3', 'fc8_1', 'prob_1']}\n",
    "\n",
    "origin_model = \"bvlcalexnet-9.onnx\"\n",
    "input_model = format_onnx(origin_model)  # name all layers according to their output tensor name\n",
    "model =  onnx.load(input_model) \n",
    "model_len = len(model.graph.node)\n",
    "\n",
    "resourceid = { 1:'lenovo_cpu0', 2:'lenovo_cpu1', 3:'lenovo_cpu2'}\n",
    "platforms = ['lenovo']\n",
    "cnn_map = {\n",
    "        'lenovo_cpu0': [ 'conv1_2', 'norm1_1', \n",
    "            'pool1_1', 'conv2_1', 'conv2_2', 'norm2_1', 'pool2_1', 'conv3_1', \n",
    "            'conv3_2', 'conv4_1', 'conv4_2', 'conv5_1', 'conv5_2', 'pool5_1', \n",
    "            'OC2_DUMMY_0', 'fc6_1', 'fc6_2'], \n",
    "         'lenovo_cpu1': ['fc6_3', 'fc7_1', 'fc7_2', 'fc7_3', 'fc8_1', 'prob_1'],\n",
    "         'lenovo_cpu2':['conv1_1']}\n",
    "\n",
    "\n",
    "split_axis = 2\n",
    "split_ranks = [0,1]\n",
    "split_points = [6,9300]\n",
    "splitnode_name = 'conv2_1'\n",
    "model =  onnx.load(input_model) \n",
    "new_model = horizontal_split(model, splitnode_name, split_ranks, split_axis, split_points)\n",
    "onnx.save(new_model, \"lip.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2eae324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  onnx.load(origin_model) \n",
    "model = onnx.shape_inference.infer_shapes(model)\n",
    "graph = model.graph\n",
    "input_map = generate_node_dict(graph.input)\n",
    "output_map = generate_node_dict(graph.output)\n",
    "initializer_map = generate_node_dict(graph.initializer)\n",
    "value_map = generate_node_dict(graph.value_info)\n",
    "node_map = generate_node_dict(graph.node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1bb0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1_1', 'conv1_2', 'norm1_1', 'pool1_1', 'conv2_1', 'conv2_2', 'norm2_1', 'pool2_1', 'conv3_1', 'conv3_2', 'conv4_1', 'conv4_2', 'conv5_1', 'conv5_2', 'pool5_1', 'OC2_DUMMY_0', 'fc6_1', 'fc6_2', 'fc6_3', 'fc7_1', 'fc7_2', 'fc7_3', 'fc8_1'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2b41b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dim_value: 1\n",
       ", dim_value: 256\n",
       ", dim_value: 26\n",
       ", dim_value: 26\n",
       "]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_map['conv2_1'].type.tensor_type.shape.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30384f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv2_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m value_map \u001b[38;5;241m=\u001b[39m generate_node_dict(graph\u001b[38;5;241m.\u001b[39mvalue_info)\n\u001b[1;32m     15\u001b[0m node_map \u001b[38;5;241m=\u001b[39m generate_node_dict(graph\u001b[38;5;241m.\u001b[39mnode)\n\u001b[0;32m---> 17\u001b[0m node_inputs \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnode_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplitnode_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39minput) \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m initializer_map]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m###############\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m### Split Input\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m###############\u001b[39;00m\n\u001b[1;32m     22\u001b[0m split_output_names \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv2_1'"
     ]
    }
   ],
   "source": [
    "split_starts = np.zeros(np.shape(split_ranks), dtype=int)\n",
    "split_ends = np.zeros(np.shape(split_ranks),  dtype=int)\n",
    "\n",
    "graph = model.graph\n",
    "for n in graph.node:\n",
    "    if n.name == '':\n",
    "        n.name = str(n.output[0])\n",
    "\n",
    "nodeIdx = find_node_index(graph, splitnode_name)\n",
    "\n",
    "input_map = generate_node_dict(graph.input)\n",
    "output_map = generate_node_dict(graph.output)\n",
    "initializer_map = generate_node_dict(graph.initializer)\n",
    "value_map = generate_node_dict(graph.value_info)\n",
    "node_map = generate_node_dict(graph.node)\n",
    "\n",
    "node_inputs = [n for n in list(node_map[splitnode_name].input) if n not in initializer_map]\n",
    "\n",
    "###############\n",
    "### Split Input\n",
    "###############\n",
    "split_output_names = []\n",
    "for i in range(len(split_ranks)):\n",
    "    split_output_names.append(splitnode_name+'_hsplit_'+str(i))\n",
    "\n",
    "gemm_attributes = {'alpha':1.0, 'beta':1.0, 'transA':0, 'transB':1}\n",
    "conv_attributes = {'auto_pad':[],'dilations':[],'group':1,'kernel_shape':[],'pads':[],'strides':[]}\n",
    "fc_attributes = {}\n",
    "node_attribute_names = []\n",
    "for i in range(len(node_map[splitnode_name].attribute)):\n",
    "    node_attribute_names.append(node_map[splitnode_name].attribute[i].name)\n",
    "\n",
    "# Get attributes of Conv layer, pads, kernel, stride, etc.\n",
    "\n",
    "if node_map[splitnode_name].op_type == 'Conv':\n",
    "    for i in range(len(node_map[splitnode_name].attribute)):\n",
    "        attribute_name = node_attribute_names[i]\n",
    "        if node_map[splitnode_name].attribute[i].ints:\n",
    "            conv_attributes[attribute_name] = node_map[splitnode_name].attribute[i].ints\n",
    "        else:\n",
    "            conv_attributes[attribute_name] = node_map[splitnode_name].attribute[i].i\n",
    "\n",
    "\n",
    "if node_map[splitnode_name].op_type == 'Gemm':   \n",
    "    for i in range(len(node_map[splitnode_name].attribute)):\n",
    "        attribute_name = node_attribute_names[i] \n",
    "        if node_map[splitnode_name].attribute[i].ints:                      \n",
    "            gemm_attributes[attribute_name] = node_map[splitnode_name].attribute[i].ints\n",
    "        else:                                    \n",
    "            gemm_attributes[attribute_name] = node_map[splitnode_name].attribute[i].i\n",
    "\n",
    "weight_names = [name for name in list(node_map[splitnode_name].input) if name in initializer_map]\n",
    "for name in weight_names:\n",
    "    if len(initializer_map[name].dims) == 4: # Cout * Cin * Kh * Kw.\n",
    "        w = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "    if len(initializer_map[name].dims) == 2: # Cout * Cin\n",
    "        w = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "    if len(initializer_map[name].dims) == 1: # Cout.\n",
    "        b = onnx.numpy_helper.to_array(initializer_map[name])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fb0707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(w)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1051bb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "split_ranks = [0,1]\n",
    "\n",
    "split_ranks = np.array(split_ranks, dtype=int)\n",
    "split_ranks = np.repeat(split_ranks, 2)\n",
    "split_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c29eb21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_starts:  [0 2]\n",
      "split_ends:  [   4 3004]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_node_index(graph, node_name):\n",
    "    idx = 0\n",
    "    for n in graph.node:\n",
    "        if n.name == node_name:\n",
    "            return idx\n",
    "        idx = idx +1\n",
    "    return -1\n",
    "\n",
    "# The protobuf definition can be found here:\n",
    "# https://github.com/onnx/onnx/blob/main/onnx/onnx.proto\n",
    "split_axis = 2\n",
    "split_ranks = [0,1]\n",
    "split_points = [3,3000]\n",
    "split_starts = np.zeros(np.shape(split_ranks), dtype=int)\n",
    "split_ends = np.zeros(np.shape(split_ranks),  dtype=int)\n",
    "\n",
    "# split_ranks = (0,1)\n",
    "# split_points = (1,3000)\n",
    "# split_starts = (0,1)\n",
    "# split_ends = (1,3001)\n",
    "split_output_names = []\n",
    "\n",
    "splitnode_name = 'conv4_1'\n",
    "#splitnode_name = 'conv1_1'\n",
    "# model = onnx.shape_inference.infer_shapes(model)\n",
    "\n",
    "graph = model.graph \n",
    "#Generate a name for all node if they have none.\n",
    "\n",
    "for n in graph.node:\n",
    "    if n.name == '':\n",
    "        n.name = str(n.output[0])\n",
    "\n",
    "nodeIdx = find_node_index(graph, splitnode_name)\n",
    "         \n",
    "        \n",
    "input_tensors = getInputlayers(input_model)\n",
    "input_map = generate_node_dict(graph.input)\n",
    "output_map = generate_node_dict(graph.output)\n",
    "initializer_map = generate_node_dict(graph.initializer)\n",
    "value_map = generate_node_dict(graph.value_info)\n",
    "node_map = generate_node_dict(graph.node)\n",
    "\n",
    "node_inputs = [n for n in list(node_map[splitnode_name].input) if n not in initializer_map]\n",
    "\n",
    "\n",
    "for i in range(len(split_ranks)):\n",
    "    split_output_names.append(splitnode_name+'_hsplit_'+str(i))\n",
    "\n",
    "    \n",
    "conv_attributes = {'auto_pad':[],'dilations':[],'group':[1],'kernel_shape':[],'pads':[],'strides':[]}\n",
    "fc_attributes = {}\n",
    "if node_map[splitnode_name].op_type == 'Conv':\n",
    "    node_attribute_names = []\n",
    "    for i in range(len(node_map[splitnode_name].attribute)):\n",
    "        node_attribute_names.append(node_map[splitnode_name].attribute[i].name)\n",
    "    for i in range(len(node_map[splitnode_name].attribute)):\n",
    "        attribute_name = node_attribute_names[i]\n",
    "        if node_map[splitnode_name].attribute[i].ints:\n",
    "            conv_attributes[attribute_name] = node_map[splitnode_name].attribute[i].ints\n",
    "        else:\n",
    "            conv_attributes[attribute_name] = node_map[splitnode_name].attribute[i].i\n",
    "\n",
    "if split_axis == -1: # do not split for the input.\n",
    "    _offset = 0\n",
    "    for i in range(len(split_ranks)):\n",
    "        split_starts[i] = 0\n",
    "        split_ends[i] = 0\n",
    "        _offset = split_ends[i]\n",
    "        \n",
    "if split_axis == 0: # channel\n",
    "    _offset = 0\n",
    "    \n",
    "    for i in range(len(split_ranks)):\n",
    "        split_starts[i] = _offset\n",
    "        split_ends[i] = _offset + split_points[i]\n",
    "        _offset = split_ends[i]\n",
    "        \n",
    "if split_axis == 1: # height\n",
    "    _offset = -conv_attributes['pads'][0] \n",
    "    for i in range(len(split_ranks)):\n",
    "        split_starts[i] = max(_offset, 0)\n",
    "        split_ends[i] = _offset + (split_points[i]-1) * conv_attributes['strides'][0] \n",
    "        _offset = split_ends[i] + conv_attributes['strides'][0]\n",
    "        split_ends[i] = max(split_ends[i]+ conv_attributes['kernel_shape'][0], 0)\n",
    "        \n",
    "if split_axis == 2: # width.\n",
    "    _offset = -conv_attributes['pads'][0] \n",
    "    for i in range(len(split_ranks)):\n",
    "        split_starts[i] = max(_offset, 0)\n",
    "        split_ends[i] = _offset + (split_points[i]-1) * conv_attributes['strides'][0] \n",
    "        _offset = split_ends[i] + conv_attributes['strides'][0] \n",
    "        split_ends[i] = max(split_ends[i]+ conv_attributes['kernel_shape'][0], 0)\n",
    "\n",
    "print (\"split_starts: \",split_starts)\n",
    "print (\"split_ends: \", split_ends)    \n",
    "    \n",
    "if split_axis<0:\n",
    "    conv_hsplit = onnx.helper.make_node(\n",
    "        name=splitnode_name + \"_hsplit\",  # Name is optional.\n",
    "        op_type = \"NSplit\",\n",
    "        inputs = node_inputs, # inputs\n",
    "        outputs=split_output_names, # outputs    \n",
    "    )    \n",
    "else:\n",
    "# Create a node (NodeProto)\n",
    "    conv_hsplit = onnx.helper.make_node(\n",
    "        name=splitnode_name + \"_hsplit\",  # Name is optional.\n",
    "        op_type = \"HSplit\",\n",
    "         inputs = node_inputs, # inputs\n",
    "        outputs=split_output_names, # outputs    \n",
    "        axis=split_axis,\n",
    "        starts=split_starts,\n",
    "        ends=split_ends,\n",
    "        sranks=split_ranks,\n",
    "        spoints=split_points,\n",
    "    )\n",
    "\n",
    "graph.node.insert(nodeIdx,conv_hsplit)\n",
    "nodeIdx = nodeIdx + 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8718979f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Convolution Layer Height\n"
     ]
    }
   ],
   "source": [
    "# graph_node_names = [n for n in list(node_map) if n in sub_node_names]\n",
    "# input_node_names = [n for n in list(input_map) if n in input_names]\n",
    "# output_node_names = [n for n in list(output_map) if n in output_names]\n",
    "splitnode_weights = {}\n",
    "splitnode_bias = {}\n",
    "\n",
    "#if node_map[splitnode_name].op_type == 'Conv':\n",
    "    if split_axis == -1:\n",
    "        print (\"Split Layer (LOP)\")\n",
    "        conv_output_names = []\n",
    "        weight_names = [name for name in list(node_map[splitnode_name].input) if name in initializer_map]\n",
    "        for name in weight_names:\n",
    "            if node_map[splitnode_name].op_type == 'Conv':\n",
    "                if len(initializer_map[name].dims) == 4: ### Cout * Cin * Kh * Kw\n",
    "                    # should be weights not bias.\n",
    "                    print (\"Split Convolution weights Channel\")\n",
    "\n",
    "                    w = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                    _offset = 0\n",
    "                    for i in range(len(split_ranks)): \n",
    "                        # split into n ranks. n = len(conv1_1_split_ranks)\n",
    "                        new_splitnode_weight_name = splitnode_name + '_w_' + str(i)\n",
    "                        splitnode_weights[new_splitnode_weight_name] = w[_offset: split_points[i]+_offset,:,:,:]\n",
    "                        _offset = _offset + split_points[i]\n",
    "            \n",
    "            if node_map[splitnode_name].op_type == 'Gemm':\n",
    "                if len(initializer_map[name].dims) == 2: # Cout * Cin\n",
    "                    # should be weights not bias. \n",
    "                    print (\"Split Fully-Connect weights Channel\")\n",
    "\n",
    "                    w = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                    _offset = 0\n",
    "                    for i in range(len(split_ranks)): \n",
    "                        # split into n ranks. n = len(conv1_1_split_ranks)\n",
    "                        new_splitnode_weight_name = splitnode_name + '_w_' + str(i)\n",
    "                        splitnode_weights[new_splitnode_weight_name] = w[_offset: split_points[i]+_offset,:]\n",
    "                        _offset = _offset + split_points[i]                                \n",
    "            if len(initializer_map[name].dims) == 1:\n",
    "                b = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                _offset = 0\n",
    "                for i in range(len(split_ranks)):                     \n",
    "                    new_splitnode_bias_name = splitnode_name + '_b_'  + str(i)\n",
    "                    splitnode_bias[new_splitnode_bias_name] = b[_offset: split_points[i]+_offset]\n",
    "                    _offset = _offset + split_points[i]\n",
    "\n",
    "\n",
    "        #conv_attributes\n",
    "        \n",
    "        for i in range(len(split_ranks)):            \n",
    "            conv1_output_node_name = splitnode_name + '_csplit_' +str(i)\n",
    "            conv_output_names.append(conv1_output_node_name)\n",
    "            # default the first rank(node) with bias.\n",
    "            W_initializer_tensor_name = splitnode_name + '_w_' + str(i)\n",
    "            W_initializer_tensor = create_initializer_tensor(\n",
    "                name=W_initializer_tensor_name,\n",
    "                tensor_array=splitnode_weights[W_initializer_tensor_name],\n",
    "                data_type=onnx.TensorProto.FLOAT)            \n",
    "            \n",
    "            B_initializer_tensor_name = splitnode_name + '_b_' + str(i)\n",
    "                \n",
    "            B_initializer_tensor = create_initializer_tensor(\n",
    "                    name=B_initializer_tensor_name,\n",
    "                    tensor_array=splitnode_bias[B_initializer_tensor_name],\n",
    "                    data_type=onnx.TensorProto.FLOAT)\n",
    "                        \n",
    "            graph.initializer.append(W_initializer_tensor)\n",
    "            graph.initializer.append(B_initializer_tensor)\n",
    "            if node_map[splitnode_name].op_type == 'Conv':\n",
    "                conv1_node = onnx.helper.make_node(\n",
    "                                name=conv1_output_node_name,  # Name is optional.\n",
    "                                op_type=\"Conv\",\n",
    "                # Must follow the order of input and output definitions.\n",
    "                # https://github.com/onnx/onnx/blob/rel-1.9.0/docs/Operators.md#inputs-2---3\n",
    "                    inputs=[\n",
    "                            splitnode_name+'_hsplit_'+str(i), W_initializer_tensor_name,\n",
    "                            B_initializer_tensor_name],\n",
    "                    outputs=[conv1_output_node_name],\n",
    "                # The following arguments are attributes.\n",
    "                    auto_pad =  conv_attributes['auto_pad'],\n",
    "                    dilations = conv_attributes['dilations'],\n",
    "                    group = conv_attributes['group'],\n",
    "                    kernel_shape = conv_attributes['kernel_shape'],\n",
    "                    pads = conv_attributes['pads'],\n",
    "                    strides = conv_attributes['strides']\n",
    "                )\n",
    "            if node_map[splitnode_name].op_type == 'Gemm':\n",
    "                conv1_node = onnx.helper.make_node(\n",
    "                                name=conv1_output_node_name,  # Name is optional.\n",
    "                                op_type=\"Gemm\",\n",
    "                # Must follow the order of input and output definitions.\n",
    "                # https://github.com/onnx/onnx/blob/rel-1.9.0/docs/Operators.md#inputs-2---3\n",
    "                    inputs=[\n",
    "                            splitnode_name+'_hsplit_'+str(i), W_initializer_tensor_name,\n",
    "                            B_initializer_tensor_name],\n",
    "                    outputs=[conv1_output_node_name],\n",
    "                # The following arguments are attributes.\n",
    "                )\n",
    "            graph.node.insert(nodeIdx, conv1_node)\n",
    "            nodeIdx = nodeIdx + 1\n",
    "        # Create a node (NodeProto)\n",
    "        conv_hsum = onnx.helper.make_node(\n",
    "            name=splitnode_name + \"_oconcat\",  # Name is optional.\n",
    "            op_type = \"Concat\",\n",
    "            inputs = conv_output_names, # inputs\n",
    "            outputs= node_map[splitnode_name].output, # outputs    \n",
    "            axis=0\n",
    "        )\n",
    "        for name in weight_names:\n",
    "            graph.input.remove(input_map[name])\n",
    "            graph.initializer.remove(initializer_map[name])\n",
    "        graph.node.insert(nodeIdx,conv_hsum)\n",
    "        nodeIdx = nodeIdx + 1\n",
    "        \n",
    "    if split_axis == 0:  \n",
    "        print (\"Split Convolution Layer Channel\")\n",
    "        conv_output_names = []\n",
    "        weight_names = [name for name in list(node_map[splitnode_name].input) if name in initializer_map]\n",
    "        for name in weight_names:\n",
    "            if len(initializer_map[name].dims) == 4:\n",
    "                # should be weights not bias.\n",
    "                print (\"Split Convolution weights Channel\")\n",
    "\n",
    "                w = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                _offset = 0\n",
    "                for i in range(len(split_ranks)): \n",
    "                    # split into n ranks. n = len(conv1_1_split_ranks)\n",
    "                    new_splitnode_weight_name = splitnode_name + '_w_' + str(i)\n",
    "                    splitnode_weights[new_splitnode_weight_name] = w[:,_offset: split_points[i]+_offset,:,:]\n",
    "                    _offset = _offset + split_points[i]\n",
    "                                \n",
    "            if len(initializer_map[name].dims) == 1:\n",
    "                b = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                new_splitnode_bias_name = splitnode_name + '_b_0' \n",
    "                splitnode_bias[new_splitnode_bias_name] = b\n",
    "\n",
    "\n",
    "        #conv_attributes   \n",
    "        for i in range(len(split_ranks)):            \n",
    "            conv1_output_node_name = splitnode_name + '_splito_' +str(i)\n",
    "            conv_output_names.append(conv1_output_node_name)\n",
    "            # default the first rank(node) with bias.\n",
    "            W_initializer_tensor_name = splitnode_name + '_w_' + str(i)\n",
    "            W_initializer_tensor = create_initializer_tensor(\n",
    "                name=W_initializer_tensor_name,\n",
    "                tensor_array=splitnode_weights[W_initializer_tensor_name],\n",
    "                data_type=onnx.TensorProto.FLOAT)            \n",
    "            \n",
    "            B_initializer_tensor_name = splitnode_name + '_b_' + str(i)\n",
    "            if i==0:    \n",
    "                B_initializer_tensor = create_initializer_tensor(\n",
    "                    name=B_initializer_tensor_name,\n",
    "                    tensor_array=splitnode_bias[B_initializer_tensor_name],\n",
    "                    data_type=onnx.TensorProto.FLOAT)\n",
    "            else:\n",
    "                B_initializer_tensor = create_initializer_tensor(\n",
    "                    name=B_initializer_tensor_name,\n",
    "                    tensor_array=np.array([],dtype=float),\n",
    "                    data_type=onnx.TensorProto.FLOAT)\n",
    "                        \n",
    "            graph.initializer.append(W_initializer_tensor)\n",
    "            graph.initializer.append(B_initializer_tensor)\n",
    "    \n",
    "            conv1_node = onnx.helper.make_node(\n",
    "                            name=conv1_output_node_name,  # Name is optional.\n",
    "                            op_type=\"Conv\",\n",
    "            # Must follow the order of input and output definitions.\n",
    "            # https://github.com/onnx/onnx/blob/rel-1.9.0/docs/Operators.md#inputs-2---3\n",
    "                inputs=[\n",
    "                        splitnode_name+'_hsplit_'+str(i), W_initializer_tensor_name,\n",
    "                        B_initializer_tensor_name],\n",
    "                outputs=[conv1_output_node_name],\n",
    "            # The following arguments are attributes.\n",
    "                auto_pad =  conv_attributes['auto_pad'],\n",
    "                dilations = conv_attributes['dilations'],\n",
    "                group = conv_attributes['group'],\n",
    "                kernel_shape = conv_attributes['kernel_shape'],\n",
    "                pads = conv_attributes['pads'],\n",
    "                strides = conv_attributes['strides']\n",
    "            )\n",
    "            \n",
    "            graph.node.insert(nodeIdx, conv1_node)\n",
    "            nodeIdx = nodeIdx + 1\n",
    "        # Create a node (NodeProto)\n",
    "        conv_hsum = onnx.helper.make_node(\n",
    "            name=splitnode_name + \"_hsum\",  # Name is optional.\n",
    "            op_type = \"HSum\",\n",
    "            inputs = conv_output_names, # inputs\n",
    "            outputs= node_map[splitnode_name].output, # outputs    \n",
    "            axis=split_axis,\n",
    "            sranks=split_ranks,\n",
    "        )\n",
    "        for name in weight_names:\n",
    "            graph.input.remove(input_map[name])\n",
    "            graph.initializer.remove(initializer_map[name])\n",
    "        graph.node.insert(nodeIdx,conv_hsum)\n",
    "        nodeIdx = nodeIdx + 1\n",
    " \n",
    "            \n",
    "                # must be bias.\n",
    "    if split_axis == 1:  \n",
    "        print (\"Split Convolution Layer Height\")    \n",
    "        conv_output_names = []\n",
    "        weight_names = [name for name in list(node_map[splitnode_name].input) if name in initializer_map]\n",
    "        for name in weight_names:\n",
    "            if len(initializer_map[name].dims) == 4:\n",
    "                # should be weights not bias.\n",
    "                w = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                for i in range(len(split_ranks)): \n",
    "                    # split into n ranks. n = len(conv1_1_split_ranks)\n",
    "                    new_splitnode_weight_name = splitnode_name + '_w_' + str(i)\n",
    "                    splitnode_weights[new_splitnode_weight_name] = w\n",
    "                    \n",
    "                                \n",
    "            if len(initializer_map[name].dims) == 1:\n",
    "                b = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                _offset = 0                \n",
    "                for i in range(len(split_ranks)): \n",
    "                    new_splitnode_bias_name = splitnode_name + '_b_' + str(i)\n",
    "                    splitnode_bias[new_splitnode_bias_name] = b\n",
    "\n",
    "\n",
    "        #conv_attributes   \n",
    "        for i in range(len(split_ranks)):            \n",
    "            conv1_output_node_name = splitnode_name + '_splith_' +str(i)\n",
    "            conv_output_names.append(conv1_output_node_name)\n",
    "            # default the first rank(node) with bias.\n",
    "            W_initializer_tensor_name = splitnode_name + '_w_' + str(i)\n",
    "            W_initializer_tensor = create_initializer_tensor(\n",
    "                name=W_initializer_tensor_name,\n",
    "                tensor_array=splitnode_weights[W_initializer_tensor_name],\n",
    "                data_type=onnx.TensorProto.FLOAT)            \n",
    "            \n",
    "            B_initializer_tensor_name = splitnode_name + '_b_' + str(i)\n",
    "            B_initializer_tensor = create_initializer_tensor(\n",
    "                    name=B_initializer_tensor_name,\n",
    "                    tensor_array=splitnode_bias[B_initializer_tensor_name],\n",
    "                    data_type=onnx.TensorProto.FLOAT)\n",
    "                        \n",
    "            graph.initializer.append(W_initializer_tensor)\n",
    "            graph.initializer.append(B_initializer_tensor)\n",
    "    \n",
    "            conv1_node = onnx.helper.make_node(\n",
    "                            name=conv1_output_node_name,  # Name is optional.\n",
    "                            op_type=\"Conv\",\n",
    "            # Must follow the order of input and output definitions.\n",
    "            # https://github.com/onnx/onnx/blob/rel-1.9.0/docs/Operators.md#inputs-2---3\n",
    "                inputs=[\n",
    "                        splitnode_name+'_hsplit_'+str(i), W_initializer_tensor_name,\n",
    "                        B_initializer_tensor_name],\n",
    "                outputs=[conv1_output_node_name],\n",
    "            # The following arguments are attributes.\n",
    "                auto_pad =  conv_attributes['auto_pad'],\n",
    "                dilations = conv_attributes['dilations'],\n",
    "                group = conv_attributes['group'],\n",
    "                kernel_shape = conv_attributes['kernel_shape'],\n",
    "                pads = conv_attributes['pads'],\n",
    "                strides = conv_attributes['strides']\n",
    "            )\n",
    "            \n",
    "            graph.node.insert(nodeIdx, conv1_node)\n",
    "            nodeIdx = nodeIdx + 1\n",
    "        # Create a node (NodeProto)\n",
    "        conv_hsum = onnx.helper.make_node(\n",
    "            name=splitnode_name + \"_hconcat\",  # Name is optional.\n",
    "            op_type = \"Concat\",\n",
    "            inputs = conv_output_names, # inputs\n",
    "            outputs= node_map[splitnode_name].output, # outputs    \n",
    "            axis=1,\n",
    "         )\n",
    "        for name in weight_names:\n",
    "            graph.input.remove(input_map[name])\n",
    "            graph.initializer.remove(initializer_map[name])\n",
    "        graph.node.insert(nodeIdx,conv_hsum)\n",
    "        nodeIdx = nodeIdx + 1\n",
    "        \n",
    "        \n",
    "    if split_axis == 2:  \n",
    "        print (\"Split Convolution Layer Width\")    \n",
    "        conv_output_names = []\n",
    "        weight_names = [name for name in list(node_map[splitnode_name].input) if name in initializer_map]\n",
    "        for name in weight_names:\n",
    "            if len(initializer_map[name].dims) == 4:\n",
    "                # should be weights not bias.\n",
    "                print (\"Split Convolution weights Channel\")\n",
    "                w = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                for i in range(len(split_ranks)): \n",
    "                    # split into n ranks. n = len(conv1_1_split_ranks)\n",
    "                    new_splitnode_weight_name = splitnode_name + '_w_' + str(i)\n",
    "                    splitnode_weights[new_splitnode_weight_name] = w\n",
    "                    \n",
    "                                \n",
    "            if len(initializer_map[name].dims) == 1:                                \n",
    "                b = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                for i in range(len(split_ranks)): \n",
    "                    b = onnx.numpy_helper.to_array(initializer_map[name]) \n",
    "                    new_splitnode_bias_name = splitnode_name + '_b_' + str(i)\n",
    "                    splitnode_bias[new_splitnode_bias_name] = b\n",
    "\n",
    "\n",
    "        #conv_attributes   \n",
    "        for i in range(len(split_ranks)):            \n",
    "            conv1_output_node_name = splitnode_name + '_splitw_' +str(i)\n",
    "            conv_output_names.append(conv1_output_node_name)\n",
    "            # default the first rank(node) with bias.\n",
    "            W_initializer_tensor_name = splitnode_name + '_w_' + str(i)\n",
    "            W_initializer_tensor = create_initializer_tensor(\n",
    "                name=W_initializer_tensor_name,\n",
    "                tensor_array=splitnode_weights[W_initializer_tensor_name],\n",
    "                data_type=onnx.TensorProto.FLOAT)            \n",
    "            \n",
    "            B_initializer_tensor_name = splitnode_name + '_b_' + str(i)\n",
    "            B_initializer_tensor = create_initializer_tensor(\n",
    "                    name=B_initializer_tensor_name,\n",
    "                    tensor_array=splitnode_bias[B_initializer_tensor_name],\n",
    "                    data_type=onnx.TensorProto.FLOAT)\n",
    "                        \n",
    "            graph.initializer.append(W_initializer_tensor)\n",
    "            graph.initializer.append(B_initializer_tensor)\n",
    "    \n",
    "            conv1_node = onnx.helper.make_node(\n",
    "                            name=conv1_output_node_name,  # Name is optional.\n",
    "                            op_type=\"Conv\",\n",
    "            # Must follow the order of input and output definitions.\n",
    "            # https://github.com/onnx/onnx/blob/rel-1.9.0/docs/Operators.md#inputs-2---3\n",
    "                inputs=[\n",
    "                        splitnode_name+'_hsplit_'+str(i), W_initializer_tensor_name,\n",
    "                        B_initializer_tensor_name],\n",
    "                outputs=[conv1_output_node_name],\n",
    "            # The following arguments are attributes.\n",
    "                auto_pad =  conv_attributes['auto_pad'],\n",
    "                dilations = conv_attributes['dilations'],\n",
    "                group = conv_attributes['group'],\n",
    "                kernel_shape = conv_attributes['kernel_shape'],\n",
    "                pads = conv_attributes['pads'],\n",
    "                strides = conv_attributes['strides']\n",
    "            )\n",
    "            \n",
    "            graph.node.insert(nodeIdx, conv1_node)\n",
    "            nodeIdx = nodeIdx + 1\n",
    "        # Create a node (NodeProto)\n",
    "        conv_hsum = onnx.helper.make_node(\n",
    "            name=splitnode_name + \"_wconcat\",  # Name is optional.\n",
    "            op_type = \"Concat\",\n",
    "            inputs = conv_output_names, # inputs\n",
    "            outputs= node_map[splitnode_name].output, # outputs    \n",
    "            axis=2,\n",
    "         )\n",
    "        for name in weight_names:\n",
    "            graph.input.remove(input_map[name])\n",
    "            graph.initializer.remove(initializer_map[name])\n",
    "        graph.node.insert(nodeIdx,conv_hsum)\n",
    "        nodeIdx = nodeIdx + 1\n",
    "        \n",
    "    nodeIdx = find_node_index(graph, splitnode_name)\n",
    "    graph.node.remove(graph.node[nodeIdx])    \n",
    "    onnx.save(model, \"modified.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d392297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2aa8861",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_1_w_0 (384, 1, 3, 3)\n",
      "conv4_1_w_1 (384, 191, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "for k, v in splitnode_weights.items():\n",
    "    print (k, np.shape(v)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5cc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda1a2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output directory ./models is created!\n",
      "Total GPU: 1, Total CPU: 6\n",
      "Consistency Check Pass.\n",
      "Devices: 1\n",
      "Generate  2  Sub-Models.\n",
      "Front End time: 5.287814 (s)\n"
     ]
    }
   ],
   "source": [
    "# call interface function to generate onnx models\n",
    "# Check whether the specified path exists or not\n",
    "output_dirs= './models'\n",
    "if not os.path.exists(output_dirs):\n",
    "  # Create a new directory because it does not exist \n",
    "  os.makedirs(output_dirs)\n",
    "  print(\"The output directory %s is created!\" % (output_dirs))\n",
    "\n",
    "start_time = time.time()\n",
    "InputSpecs = Interface(model=input_model, mappings=cnn_map, platforms=platforms)\n",
    "print (\"Front End time: %f (s)\"%(time.time() - start_time))\n",
    "output_dirs = 'models'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d29a3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cpp code \n",
    "GenerateCode = EngineCode(\n",
    "    CppName = \"./models/multinode\",\n",
    "    Platforms = InputSpecs.platforms,\n",
    "    NodesList = InputSpecs.nodes,\n",
    "    ComputingNodes = InputSpecs.computingnodes,\n",
    "    ValueInfos = InputSpecs.value_map,\n",
    "    Inputs = InputSpecs.inputs,\n",
    "    Outputs = InputSpecs.outputs,\n",
    "    Benchmark = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
